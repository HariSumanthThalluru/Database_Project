{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "5ea38037-44b9-432a-8302-ea9c3a7765c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   StudentID FirstName  LastName   Course  Professor  ProfessorEmail  \\\n",
      "0        101      John       Doe  Math101   Dr.Smith   smith@mst.edu   \n",
      "1        102      Jane       Roe  Math101   Dr.Smith   smith@mst.edu   \n",
      "2        103   Arindam    Khanda    CS101   Dr.Jones   jones@mst.edu   \n",
      "3        104      Jose  Franklin   Bio101  Dr.Watson  watson@mst.edu   \n",
      "4        105       Ada  Lovelace    CS101   Dr.Jones   jones@mst.edu   \n",
      "\n",
      "  CourseStart CourseEnd  \n",
      "0      1/1/23   5/30/23  \n",
      "1      1/1/23   5/30/23  \n",
      "2      2/1/23   6/15/23  \n",
      "3      3/1/23   7/20/23  \n",
      "4      2/1/23   6/15/23  \n",
      "\n",
      "\n",
      "Dependencies\n",
      "{('StudentID',): ['FirstName', 'LastName'], ('Course',): ['CourseStart', 'CourseEnd', 'Professor'], ('Professor',): ['ProfessorEmail']}\n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stdin",
     "output_type": "stream",
     "text": [
      "Select the highest normal form to normalize (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF):  B\n",
      "Determine the highest normal form of the given relation? (1: Yes, 2: No):  1\n",
      "Enter the primary key values seperated with commas:  StudentID,Course\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "\n",
      "CREATE TABLE StudentID_table (\n",
      "  StudentID VARCHAR(255) PRIMARY KEY,\n",
      "  FirstName VARCHAR(255),\n",
      "  LastName VARCHAR(255)\n",
      ");\n",
      "CREATE TABLE Course_table (\n",
      "  Course VARCHAR(255) PRIMARY KEY,\n",
      "  CourseStart VARCHAR(255),\n",
      "  CourseEnd VARCHAR(255),\n",
      " FOREIGN KEY (Professor_fk)\n",
      ");\n",
      "CREATE TABLE Professor_table (\n",
      "  Professor VARCHAR(255) PRIMARY KEY,\n",
      "  ProfessorEmail VARCHAR(255)\n",
      ");\n",
      "\n",
      "\n",
      "The Highest Normal Form of the given table is: 1NF\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import csv\n",
    "from itertools import combinations\n",
    "import re\n",
    "\n",
    "\n",
    "# Read the csv file and functional dependencies file\n",
    "file = pd.read_csv('exampleInputTable.csv')\n",
    "print(file)\n",
    "print('\\n')\n",
    "\n",
    "with open('data.txt', 'r') as f:\n",
    "    lines = [line.strip() for line in f]\n",
    "\n",
    "dependencies = {}\n",
    "for line in lines:\n",
    "    determ, depend = line.split(\" -> \")\n",
    "    # Seperating the determ by comma inorder to make a list\n",
    "    determ = determ.split(\", \")\n",
    "    dependencies[tuple(determ)] = depend.split(\", \")\n",
    "print('Dependencies')\n",
    "print(dependencies)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# Taking input from user\n",
    "max_normal_form = input(\"Select the highest normal form to normalize (1: 1NF, 2: 2NF, 3: 3NF, B: BCNF, 4: 4NF, 5: 5NF): \")\n",
    "if max_normal_form in [\"1\", \"2\", \"3\", \"4\", \"5\"]:\n",
    "    max_normal_form = int(max_normal_form)\n",
    "\n",
    "# To determine the highest normal form of the relation\n",
    "find_high_normalform = int(\n",
    "    input('Determine the highest normal form of the given relation? (1: Yes, 2: No): '))\n",
    "high_normalform = 'not normalized'\n",
    "\n",
    "\n",
    "# Enter Key\n",
    "primary_key = input(\n",
    "    \"Enter the primary key values seperated with commas: \").split(', ')\n",
    "print('\\n')\n",
    "\n",
    "keys = ()\n",
    "for key in primary_key:\n",
    "    keys = keys + (key,)\n",
    "\n",
    "primary_key = keys\n",
    "\n",
    "\n",
    "def contains_comma(series):\n",
    "    return series.str.contains(',').any()\n",
    "\n",
    "\n",
    "def parser(file):\n",
    "    file = file.astype(str)\n",
    "    columns_with_commas = [\n",
    "        col for col in file.columns if contains_comma(file[col])]\n",
    "\n",
    "    for col in columns_with_commas:\n",
    "        file[col] = file[col].str.split(\n",
    "            ',').apply(lambda x: [item.strip() for item in x])\n",
    "\n",
    "    return file\n",
    "file = parser(file)\n",
    "\n",
    "multivalue = {}\n",
    "if not max_normal_form == 'B' and max_normal_form >= 4:\n",
    "    with open('mvd.txt', 'r') as fil:\n",
    "        mvd_lines = [line.strip() for line in fil]\n",
    "\n",
    "    print(mvd_lines)\n",
    "\n",
    "    for mvd in mvd_lines:\n",
    "        determ, depend = mvd.split(\" ->> \")\n",
    "        determ = determ.split(\n",
    "            \", \") if \", \" in determ else [determ]\n",
    "        determ_str = str(determ)\n",
    "        if determ_str in multivalue:\n",
    "            multivalue[determ_str].append(depend)\n",
    "        else:\n",
    "            multivalue[determ_str] = [depend]\n",
    "\n",
    "\n",
    "def is_list_or_set(item):\n",
    "    return isinstance(item, (list, set))\n",
    "\n",
    "\n",
    "def is_superkey(rel, determ):\n",
    "    grouped = rel.groupby(\n",
    "        list(determ)).size().reset_index(name='count')\n",
    "    return not any(grouped['count'] > 1)\n",
    "\n",
    "\n",
    "def powerset(s):\n",
    "    x = len(s)\n",
    "    for i in range(1 << x):\n",
    "        yield [s[j] for j in range(x) if (i & (1 << j)) > 0]\n",
    "\n",
    "\n",
    "def bcnf_decomp(rel, dependencies):\n",
    "    for determ, depends in dependencies.items():\n",
    "        if set(determ).issubset(rel.columns) and not is_superkey(rel, determ):\n",
    "            depend_cols = list(determ) + depends\n",
    "            new_rel1 = rel[depend_cols].drop_duplicates()\n",
    "            remaining_cols = list(set(rel.columns) - set(depends))\n",
    "            new_rel2 = rel[remaining_cols].drop_duplicates()\n",
    "            return [new_rel1, new_rel2]\n",
    "    return [rel]\n",
    "\n",
    "\n",
    "def in_1nf(rel):\n",
    "    if rel.empty:\n",
    "        return False\n",
    "\n",
    "    for column in rel.columns:\n",
    "        unique_types = rel[column].apply(type).nunique()\n",
    "        if unique_types > 1:\n",
    "            return False\n",
    "        if rel[column].apply(lambda x: isinstance(x, (list, dict, set))).any():\n",
    "            return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def in_2nf(primary_key, dependencies):\n",
    "    for determs, depend in dependencies.items(): \n",
    "        # Check if X is a superkey\n",
    "        superkey = True\n",
    "        for x in determs:\n",
    "            if x not in file.columns:\n",
    "                superkey = False\n",
    "                break\n",
    "        if superkey:\n",
    "            # Check if Y is fully depend on X\n",
    "            for y in depend:\n",
    "                if y not in file.columns or y not in determs:\n",
    "                    return False\n",
    "    return True \n",
    "\n",
    "\n",
    "\n",
    "def in_3nf(rels, dependencies):\n",
    "    i = 0\n",
    "    keys_as_list = list(dependencies.keys())\n",
    "    for rel in rels:\n",
    "        attributes = set(rels[rel].columns)\n",
    "        non_prime_attributes = attributes - set(rel)\n",
    "        i += 1\n",
    "\n",
    "        for determ, depends in dependencies.items():\n",
    "            if all(attr in non_prime_attributes for attr in determ):\n",
    "                for depend in depends:\n",
    "                    if depend in non_prime_attributes:\n",
    "                        return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def in_bcnf(rels, primary_key, dependencies):\n",
    "    for rel in rels:\n",
    "        for determ, depends in dependencies.items():\n",
    "            if set(determ).issubset(rel.columns):\n",
    "                if not is_superkey(rel, determ):\n",
    "                    return False\n",
    "    return True\n",
    "\n",
    "\n",
    "def in_4nf(rels, multivalue):\n",
    "    for rel in rels:\n",
    "        for determ, depends in multivalue.items():\n",
    "            for depend in depends:\n",
    "                if isinstance(determ, tuple):\n",
    "                    determ_cols = list(determ)\n",
    "                else:\n",
    "                    determ_cols = [determ]\n",
    "\n",
    "                if all(col in rel.columns for col in determ_cols + [depend]):\n",
    "                    grouped = rel.groupby(determ_cols)[\n",
    "                        depend].apply(set).reset_index()\n",
    "                    if len(grouped) < len(rel):\n",
    "                        print(\n",
    "                            f\"violation of multi-valued dependencies: {determ} ->> {depend}\")\n",
    "                        return False\n",
    "\n",
    "    return True\n",
    "\n",
    "\n",
    "def in_5nf(rels):\n",
    "    i = 0\n",
    "    candidate_keys_dict = {}\n",
    "    for rel in rels:\n",
    "        print(rel)\n",
    "        user_input = input(\"Enter the candidate keys \")\n",
    "        print('\\n')\n",
    "        tuples = re.findall(r'\\((.*?)\\)', user_input)\n",
    "        candidate_keys = [tuple(map(str.strip, t.split(','))) for t in tuples]\n",
    "        candidate_keys_dict[i] = candidate_keys\n",
    "        i += 1\n",
    "\n",
    "    print(f'the Candidate Keys for given relation:')\n",
    "    print(candidate_keys_dict)\n",
    "    print('\\n')\n",
    "\n",
    "    j = 0\n",
    "    for rel in rels:\n",
    "        candidate_keys = candidate_keys_dict[j]\n",
    "        j += 1\n",
    "\n",
    "        data_tuples = [tuple(row) for row in rel.to_numpy()]\n",
    "\n",
    "        \n",
    "        def project(data, attributes):\n",
    "            return {tuple(row[attr] for attr in attributes) for row in data}\n",
    "\n",
    "        # to check if the given attributes are a super key\n",
    "        def is_superkey(attributes):\n",
    "            for key in candidate_keys:\n",
    "                if set(key).issubset(attributes):\n",
    "                    return True\n",
    "            return False, candidate_keys_dict\n",
    "\n",
    "        for i in range(1, len(rel.columns)):\n",
    "            for attrs in combinations(rel.columns, i):\n",
    "                \n",
    "                if is_superkey(attrs):\n",
    "                    continue\n",
    "\n",
    "                # Project the data onto the attributes and their complement\n",
    "                projected_data = project(data_tuples, attrs)\n",
    "                complement_attrs = set(rel.columns) - set(attrs)\n",
    "                complement_data = project(data_tuples, complement_attrs)\n",
    "                # combine the projected data and check whether it is equals to the original data\n",
    "\n",
    "                \n",
    "                joined_data = {(row1 + row2)\n",
    "                               for row1 in projected_data for row2 in complement_data}\n",
    "                if set(data_tuples) != joined_data:\n",
    "                    print(\"Not satisfy 5NF then check attribures:\", attrs)\n",
    "                    return False, candidate_keys_dict\n",
    "\n",
    "    return True, candidate_keys_dict\n",
    "\n",
    "def first_normal_form(rel):\n",
    "    one_flag = in_1nf(rel)\n",
    "\n",
    "    if one_flag:\n",
    "        return rel, one_flag\n",
    "    else:\n",
    "        for col in rel.columns:\n",
    "            if rel[col].apply(is_list_or_set).any():\n",
    "                rel = rel.explode(col)\n",
    "\n",
    "        return rel, one_flag\n",
    "\n",
    "def second_normal_form(rel, primary_key, dependencies):\n",
    "    rels = {}\n",
    "    original_rel = rel\n",
    "    two_flag = in_2nf(primary_key, dependencies)\n",
    "\n",
    "    if two_flag:\n",
    "        rels[primary_key] = rel\n",
    "        return rels, two_flag\n",
    "    else:\n",
    "        depend_keys = list(dependencies.keys())\n",
    "        for determ, depends in dependencies.items():\n",
    "            modified_depends = [\n",
    "                dep + '_fk' if (dep,) in depend_keys else dep for dep in depends]\n",
    "\n",
    "            cols = list(determ) + depends\n",
    "            rels[tuple(determ)] = rel[cols].drop_duplicates(\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            rename_dict = {dep: modified_dep for dep,\n",
    "                           modified_dep in zip(depends, modified_depends)}\n",
    "            rels[tuple(determ)].rename(\n",
    "                columns=rename_dict, inplace=True)\n",
    "\n",
    "        junc_cols = []\n",
    "        rel_name = ''\n",
    "        for rel in rels:\n",
    "            if set(rel).issubset(primary_key):\n",
    "                rel_name += \"_\".join(rel)\n",
    "                junc_cols.append(rel)\n",
    "\n",
    "        if len(junc_cols) > 1:\n",
    "            jun_cols = list(junc_cols)\n",
    "            cols = [element for tup in jun_cols for element in tup]\n",
    "            temp_df = original_rel[cols].drop_duplicates(\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            renamed_cols = [col + '_fk' for col in cols]\n",
    "            temp_df.columns = renamed_cols + \\\n",
    "                [col for col in temp_df.columns if col not in cols]\n",
    "\n",
    "            temp_df[rel_name] = range(1, len(temp_df) + 1)\n",
    "            col_order = [rel_name] + renamed_cols\n",
    "            temp_df = temp_df[columns_order]\n",
    "            rels[rel_name] = temp_df\n",
    "\n",
    "\n",
    "        return rels, two_flag\n",
    "\n",
    "\n",
    "def third_normal_form(rels, primary_key, dependencies):\n",
    "    three_rels = {}\n",
    "    original_rel = rels\n",
    "    three_flag = in_3nf(rels, dependencies)\n",
    "\n",
    "    if three_flag:\n",
    "        return rels, three_flag\n",
    "    else:\n",
    "        depend_keys = list(dependencies.keys())\n",
    "        for rel in rels:\n",
    "            original_rel = rels[rel]\n",
    "            for determ, depends in dependencies.items():\n",
    "                modified_depends = [\n",
    "                    dep + '_fk' if (dep,) in depend_keys else dep for dep in depends]\n",
    "\n",
    "                cols = list(determ) + depends\n",
    "                three_rels[tuple(determ)] = rels[rel][cols].drop_duplicates(\n",
    "                ).reset_index(drop=True)\n",
    "\n",
    "                rename_dict = {dep: modified_dep for dep,\n",
    "                               modified_dep in zip(depends, modified_depends)}\n",
    "                three_rels[tuple(determ)].rename(\n",
    "                    columns=rename_dict, inplace=True)\n",
    "\n",
    "        junc_cols = []\n",
    "\n",
    "        rel_name = ''\n",
    "        for rel in three_rel:\n",
    "            rel_name += \"_\".join(rel)\n",
    "            junc_cols.append(rel)\n",
    "\n",
    "        if len(junc_cols) > 1:\n",
    "            jun_cols = list(junc_cols)\n",
    "            cols = [element for tup in jun_cols for element in tup]\n",
    "            temp_df = original_rel[cols].drop_duplicates(\n",
    "            ).reset_index(drop=True)\n",
    "\n",
    "            renamed_cols = [col + '_fk' for col in cols]\n",
    "            temp_df.columns = renamed_cols + \\\n",
    "                [col for col in temp_df.columns if col not in cols]\n",
    "\n",
    "            temp_df[rel_name] = range(1, len(temp_df) + 1)\n",
    "            col_order = [rel_name] + renamed_cols\n",
    "            temp_df = temp_df[columns_order]\n",
    "            three_rels[rel_name] = temp_df\n",
    "\n",
    "        return three_rels, three_flag\n",
    "\n",
    "\n",
    "def bc_normal_form(rels, primary_key, dependencies):\n",
    "    rels = list(rels.values())\n",
    "    bcnf_rels = []\n",
    "    bcnf_flag = in_bcnf(rels, primary_key, dependencies)\n",
    "\n",
    "    if bcnf_flag:\n",
    "        return rels, bcnf_flag\n",
    "    else:\n",
    "        for rel in rels:\n",
    "            bcnf_decomp_rel = bcnf_decomp(\n",
    "                rel, dependencies)\n",
    "            if len(bcnf_decomp_rel) == 1:\n",
    "                bcnf_rels.append(bcnf_decomp_rel)\n",
    "            else:\n",
    "                rels.extend(bcnf_decomp_rel)\n",
    "\n",
    "    return bcnf_rels, bcnf_flag\n",
    "\n",
    "\n",
    "def fourth_normal_form(rels, multivalue):\n",
    "    four_rels = []\n",
    "    four_flag = in_4nf(rels, multivalue)\n",
    "\n",
    "    if four_flag:\n",
    "        return rels, four_flag\n",
    "    else:\n",
    "        for rel in rels:\n",
    "            for determ, depends in multivalue.items():\n",
    "                for depend in depends:\n",
    "                    if isinstance(determ, tuple):\n",
    "                        determ_cols = list(determ)\n",
    "                    else:\n",
    "                        determ_cols = [determ]\n",
    "\n",
    "                    if all(col in rel.columns for col in determ_cols + [depend]):\n",
    "                        grouped = rel.groupby(determ_cols)[\n",
    "                            depend].apply(set).reset_index()\n",
    "                        if len(grouped) < len(rel):\n",
    "                            # Decomposition\n",
    "                            table_1 = rel[determ_cols +\n",
    "                                               [depend]].drop_duplicates()\n",
    "                            table_2 = rel[determ_cols + [col for col in rel.columns if col not in [\n",
    "                                depend] + determ_cols]].drop_duplicates()\n",
    "\n",
    "                        \n",
    "                            four_rels.extend([table_1, table_2])\n",
    "\n",
    "                            break\n",
    "                else:\n",
    "                    continue\n",
    "                break\n",
    "            else:\n",
    "                four_rels.append(rel)\n",
    "\n",
    "    if len(four_rels) == len(rels):\n",
    "        return four_rels  # relations are in 4NF\n",
    "    else:\n",
    "        return fourth_normal_form(four_rels, multivalue)\n",
    "\n",
    "\n",
    "def decomposing_to_5nf(dataframe, candidate_keys):\n",
    "    \n",
    "    def project(df, attributes):\n",
    "        return df[list(attributes)].drop_duplicates().reset_index(drop=True)\n",
    "\n",
    "    # find whether the decomposition is loseless\n",
    "    def is_lossless(df, df1, df2):\n",
    "        common_columns = set(df1.columns) & set(df2.columns)\n",
    "        if not common_columns:\n",
    "            return False\n",
    "        joined_df = pd.merge(df1, df2, how='inner', on=list(common_columns))\n",
    "        return df.equals(joined_df)\n",
    "\n",
    "    decomposed_tables = [dataframe]\n",
    "\n",
    "    # check for each candidate key and thn decompose the table\n",
    "    for key in candidate_keys:\n",
    "        new_tables = []\n",
    "        for table in decomposed_tables:\n",
    "            if set(key).issubset(set(table.columns)):\n",
    "                table1 = project(table, key)\n",
    "                remaining_columns = set(table.columns) - set(key)\n",
    "                table2 = project(table, remaining_columns | set(key))\n",
    "\n",
    "                # Check if the decomposition is lossless\n",
    "                if is_lossless(table, table1, table2):\n",
    "                    new_tables.extend([table1, table2])\n",
    "                else:\n",
    "                    new_tables.append(table)\n",
    "            else:\n",
    "                new_tables.append(table)\n",
    "        decomposed_tables = new_tables\n",
    "\n",
    "    return decomposed_tables\n",
    "\n",
    "\n",
    "def fifth_normal_form(rels, primary_key, dependencies):\n",
    "    five_rels = []\n",
    "    five_flag, candidate_keys_dict = in_5nf(rels)\n",
    "\n",
    "    if five_flag:\n",
    "        return rels, five_flag\n",
    "    else:\n",
    "        i = 0\n",
    "        for rel in rels:\n",
    "            candidate_keys = candidate_keys_dict[i]\n",
    "            i += 1\n",
    "            decomposed_rels = decomposing_to_5nf(rel, candidate_keys)\n",
    "            five_rels.append(decomposed_rels)\n",
    "\n",
    "    return five_rels, five_flag\n",
    "\n",
    "# Used to generate output as per the requirement\n",
    "def output(dtype):\n",
    "    \"\"\"change pandas dtype to SQL data type.\"\"\"\n",
    "    if \"int\" in str(dtype):\n",
    "        return \"INT\"\n",
    "    elif \"float\" in str(dtype):\n",
    "        return \"FLOAT\"\n",
    "    elif \"object\" in str(dtype):\n",
    "        return \"VARCHAR(255)\"\n",
    "    elif \"datetime\" in str(dtype):\n",
    "        return \"DATETIME\"\n",
    "    else:\n",
    "        return \"TEXT\"\n",
    "\n",
    "\n",
    "def sql_query_1NF(primary_keys, df):\n",
    "    t_name = \"_\".join(primary_keys) + \"_table\"\n",
    "\n",
    "    # Create SQL Query\n",
    "    query = f\"CREATE TABLE {t_name} (\\n\"\n",
    "\n",
    "    # Iterate through columns to create query\n",
    "    for col, dtype in zip(df.columns, df.dtypes):\n",
    "        if col in primary_keys:\n",
    "            query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
    "        else:\n",
    "            query += f\"  {col} {output(dtype)},\\n\"\n",
    "\n",
    "    \n",
    "    query = query.rstrip(',\\n') + \"\\n);\"\n",
    "\n",
    "    print(query)\n",
    "\n",
    "\n",
    "\n",
    "def sql_query_2_3(rels):\n",
    "    for rel in rels:\n",
    "        primary_keys = rel\n",
    "        primary_keys = (primary_keys,) if isinstance(\n",
    "        primary_keys, str) else primary_keys\n",
    "        t_name = \"_\".join(primary_keys) + '_table'\n",
    "        rel = rels[rel]\n",
    "\n",
    "        # Create SQL Query\n",
    "        query = f\"CREATE TABLE {t_name} (\\n\"\n",
    "\n",
    "        # Iterate through columns to create query\n",
    "        for col, dtype in zip(rel.columns, rel.dtypes):\n",
    "            if col in primary_keys:\n",
    "                query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
    "            elif '_fk' in col:\n",
    "                query += f\" FOREIGN KEY ({col}) REFERENCES {col.replace('_fk','')}_table({col.replace('_fk','')}),\\n\"\n",
    "            else:\n",
    "                query += f\"  {col} {output(dtype)},\\n\"\n",
    "\n",
    "        \n",
    "        query = query.rstrip(',\\n') + \"\\n);\"\n",
    "\n",
    "        print(query)\n",
    "\n",
    "\n",
    "def sql_query_BCNF_4_5(rels):\n",
    "    for rel in rels:\n",
    "        primary_key = rel.columns[0]\n",
    "        t_name = f'{primary_key}_table'\n",
    "\n",
    "        # Create SQL Query\n",
    "        query = f\"CREATE TABLE {t_name} (\\n\"\n",
    "\n",
    "        # Iterate through columns to create query\n",
    "        for col, dtype in zip(rel.columns, rel.dtypes):\n",
    "            if col == primary_key:\n",
    "                query += f\"  {col} {output(dtype)} PRIMARY KEY,\\n\"\n",
    "            elif '_fk' in col:\n",
    "                query += f\" FOREIGN KEY ({col}),\\n\"\n",
    "            else:\n",
    "                query += f\"  {col} {output(dtype)},\\n\"\n",
    "\n",
    "        \n",
    "        query = query.rstrip(',\\n') + \"\\n);\"\n",
    "\n",
    "        print(query)\n",
    "\n",
    "if max_normal_form == 'B' or max_normal_form >= 1:\n",
    "    onenf_table, one_flag = first_normal_form(\n",
    "        file)\n",
    "    if one_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: 1NF'\n",
    "        \n",
    "    if max_normal_form == 1:\n",
    "        if one_flag:\n",
    "            print('The table is already in 1NF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_1NF(primary_key, onenf_table)\n",
    "\n",
    "if max_normal_form == 'B' or max_normal_form >= 2:\n",
    "    twonf_tables, two_flag = second_normal_form(\n",
    "        onenf_table, primary_key, dependencies)\n",
    "    if one_flag and two_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: 2NF'\n",
    "\n",
    "    if max_normal_form == 2:\n",
    "        if two_flag and one_flag:\n",
    "            print('The table is already in 2NF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_2_3(twonf_tables)\n",
    "\n",
    "if max_normal_form == 'B' or max_normal_form >= 3:\n",
    "    threenf_tables, three_flag = third_normal_form(\n",
    "        twonf_tables, primary_key, dependencies)\n",
    "    \n",
    "    if one_flag and two_flag and three_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: 3NF'\n",
    "        \n",
    "    if max_normal_form == 3:\n",
    "        if three_flag and two_flag and one_flag:\n",
    "            print('The table is already in 3NF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_2_3(threenf_tables)\n",
    "\n",
    "if max_normal_form == 'B' or max_normal_form >= 4:\n",
    "    bcnf_tables, bcnf_flag = bc_normal_form(\n",
    "        threenf_tables, primary_key, dependencies)\n",
    "    \n",
    "    if one_flag and two_flag and three_flag and bcnf_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: BCNF'\n",
    "        \n",
    "    if max_normal_form == 'B':\n",
    "        if bcnf_flag and three_flag and two_flag and one_flag:\n",
    "            print('The table is already in BCNF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_BCNF_4_5(bcnf_tables)\n",
    "\n",
    "if not max_normal_form == 'B' and max_normal_form >= 4:\n",
    "    fournf_tables, four_flag = fourth_normal_form(\n",
    "        bcnf_tables, multivalue)\n",
    "    \n",
    "    if one_flag and two_flag and three_flag and bcnf_flag and four_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: 4NF'\n",
    "        \n",
    "    if max_normal_form == 4:\n",
    "        if four_flag and bcnf_flag and three_flag and two_flag and one_flag:\n",
    "            print('The table is already in 4NF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_BCNF_4_5(fournf_tables)\n",
    "\n",
    "if not max_normal_form == 'B' and max_normal_form >= 5:\n",
    "    fivenf_tables, five_flag = fifth_normal_form(\n",
    "        fournf_tables, primary_key, dependencies)\n",
    "    \n",
    "    if one_flag and two_flag and three_flag and bcnf_flag and four_flag and five_flag:\n",
    "        high_normalform = 'The Highest Normal Form of the given table is: 5NF'\n",
    "        \n",
    "    if max_normal_form == 5:\n",
    "        if five_flag and four_flag and bcnf_flag and three_flag and two_flag and one_flag:\n",
    "            print('The table is already in 5NF')\n",
    "            print('\\n')\n",
    "\n",
    "        sql_query_BCNF_4_5(fivenf_tables)\n",
    "        \n",
    "if find_high_normalform == 1:\n",
    "    print('\\n')\n",
    "    print(high_normalform)\n",
    "    print('\\n')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a097c38-4904-4a47-ab94-78d5b29dd832",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
